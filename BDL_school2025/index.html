<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-4a990d8dcb58f517c7c86712b8f2ac7c.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.31">

  <meta name="author" content="Wassim Kabalan">
  <meta name="author" content="Alexandre Boucaud, Fran√ßois Lanusse">
  <title>Bayesian Inference for Cosmology with JAX</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #24292e;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #24292e; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #d73a49; } /* Attribute */
    code span.bn { color: #005cc5; } /* BaseN */
    code span.bu { color: #d73a49; } /* BuiltIn */
    code span.cf { color: #d73a49; } /* ControlFlow */
    code span.ch { color: #032f62; } /* Char */
    code span.cn { color: #005cc5; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #d73a49; } /* DataType */
    code span.dv { color: #005cc5; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #d73a49; font-weight: bold; } /* Extension */
    code span.fl { color: #005cc5; } /* Float */
    code span.fu { color: #6f42c1; } /* Function */
    code span.im { color: #032f62; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #d73a49; } /* Keyword */
    code span.op { color: #24292e; } /* Operator */
    code span.ot { color: #6f42c1; } /* Other */
    code span.pp { color: #d73a49; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #005cc5; } /* SpecialChar */
    code span.ss { color: #032f62; } /* SpecialString */
    code span.st { color: #032f62; } /* String */
    code span.va { color: #e36209; } /* Variable */
    code span.vs { color: #032f62; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-8b3c6da0781682310500f0ce9cbdf807.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="assets/titles/bayes_title_1.png" data-background-opacity="0.8" data-background-size="fill" class="center">
  <h1 class="title"><span style="color:#ffffff; font-size: largest;">Bayesian Inference for Cosmology with JAX</span></h1>
  <p class="author"><span style="color:#ffffff; font-size: larger;">Wassim Kabalan</span></p>
  <p class="author"><span style="color:#ffffff; font-size: Smaller;">Alexandre Boucaud, Fran√ßois Lanusse</span></p>
  <div style=""></div>
<div style="margin-top: 20px; text-align: center;align-items: bottom;">
  <div style="display: flex; justify-content: space-around; align-items: center; layout-valign=" middle"=""> <img src="assets/Logos/AstroDeep-2.png" style="width: 35%;"> <img src="assets/Logos/APC.png" style="width: 20%;"> <img src="assets/Logos/scipol.png" style="width: 35%;"> </div>
</div>

</section>
<section id="outline-for-this-presentation" class="slide level2">
<h2>Outline for This Presentation</h2>
<div class="solutionbox">
<div class="solutionbox-body" style="font-size: 22px; border-radius: 10px; border: 2px solid #3b0a68;">
<ul>
<li><span style="color:#3b0a68; font-size: 26px;"><strong>Understand Cosmological Inference</strong></span>: Learn how we go from observations to cosmological parameters. <br><br></li>
<li><span style="color:#3b0a68; font-size: 26px;"><strong>From œá¬≤ to Bayesian Inference</strong></span>: See how Bayesian modeling generalizes classical approaches. <br><br></li>
<li><span style="color:#3b0a68; font-size: 26px;"><strong>Learn Forward Modeling and Hierarchical Models</strong></span>: Understand generative models and field-level inference. <br><br></li>
<li><span style="color:#3b0a68; font-size: 26px;"><strong>Explore Modern Tools (JAX, NumPyro, BlackJAX)</strong></span>: Use practical libraries for scalable inference. <br><br></li>
<li><span style="color:#3b0a68; font-size: 26px;"><strong>Prepare for Hands-On Notebooks</strong></span>: Apply Bayesian techniques in real examples using JAX.</li>
</ul>
</div>
</div>
<aside class="notes">
<p>‚ÄúLet me walk you through what we‚Äôre aiming to cover today.‚Äù</p>
<ul>
<li><p><strong>First</strong>, we‚Äôll build an understanding of <strong>cosmological inference</strong> ‚Äî how we move from raw observational data to constraints on cosmological parameters. This includes both the intuition and the mathematical machinery behind it.</p></li>
<li><p><strong>Second</strong>, we‚Äôll see how <strong>Bayesian inference</strong> generalizes the classical approach. Instead of just optimizing a œá¬≤, we model uncertainty and latent structure more fully.</p></li>
<li><p><strong>Third</strong>, we‚Äôll dive into <strong>forward modeling</strong> and <strong>hierarchical models</strong>. These are especially relevant in modern cosmology where we simulate the full data generation process and marginalize over latent variables.</p></li>
<li><p>Then we‚Äôll explore some of the <strong>modern tools</strong> that make all of this practical: <strong>JAX</strong> for fast, differentiable computing; <strong>NumPyro</strong> for probabilistic programming; and <strong>BlackJAX</strong> for flexible sampling.</p></li>
<li><p>Finally, the goal is for you to leave prepared for the <strong>hands-on notebooks</strong>, where you‚Äôll implement and explore real inference pipelines using JAX-based tools.</p></li>
</ul>
<p>The goal of this is to able to start doing bayesian inference .. so if you have any questions, please ask them during the presentation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section>
<section id="background-inference-in-cosmology-the-big-picture" class="title-slide slide level1 center">
<h1>Background : Inference in Cosmology: The Big Picture</h1>

</section>
<section id="inference-in-cosmology-the-frequentist-pipeline" class="slide level2" style="font-size: 21px;">
<h2>Inference in Cosmology: The Frequentist Pipeline</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><br></p>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/freq_pipeline_0.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/freq_pipeline_1.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/freq_pipeline_2.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/freq_pipeline_3.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="5">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/freq_pipeline_4.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<div class="fragment fade-in" data-fragment-index="1">
<ul>
<li><strong>cosmological parameters</strong> (Œ©): matter density, dark energy, etc.</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<ul>
<li>Predict observables: <strong>CMB, galaxies, lensing</strong></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<ul>
<li>Extract <strong>summary statistics</strong>: <span class="math inline">\(P(k)\)</span>, <span class="math inline">\(C_\ell\)</span> , 2PCF</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<ul>
<li>Compute <strong>likelihood</strong>: <span class="math inline">\(L(\Omega \vert data)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="5">
<ul>
<li>Estimate <span class="math inline">\(\hat{\Omega}\)</span> via <strong>maximization</strong> (<span class="math inline">\(\chi^2\)</span> fitting)</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="6">
<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 20px;">
<p><strong>Frequentist Toolbox</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 18px;">
<ul>
<li>Optimizers/Gradient descent</li>
<li>2-point correlation function (2PCF)</li>
<li>Power spectrum fitting: <span class="math inline">\(P(k)\)</span>, <span class="math inline">\(C_\ell\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>‚ÄúThis is the traditional approach many of you are already familiar with ‚Äî the frequentist pipeline.‚Äù</p>
<ul>
<li><p>We start with a set of <strong>cosmological parameters</strong>, denoted here as <strong>Œ©</strong> ‚Äî this could include things like the matter density, dark energy equation of state, etc.</p></li>
<li><p>These parameters are used to predict observable quantities, such as the <strong>CMB power spectrum</strong>, <strong>galaxy clustering</strong>, or <strong>weak lensing shear</strong>.</p></li>
<li><p>From the data, we extract <strong>summary statistics</strong> ‚Äî typically things like <strong>2-point correlation functions</strong>, <strong>power spectra</strong> (P(k), C_‚Ñì), or other reduced forms of the data.</p></li>
<li><p>Then, we compute a <strong>likelihood</strong> ‚Äî usually assuming a Gaussian form for the summary statistics ‚Äî and estimate parameters by <strong>maximizing this likelihood</strong>. That gives us a point estimate <strong>Œ©ÃÇ</strong>.</p></li>
<li><p>This pipeline works well when:</p>
<ul>
<li>You have a reliable analytic likelihood,</li>
<li>The summary statistics are informative,</li>
<li>And the assumptions (e.g.&nbsp;Gaussianity, linear regime) hold.</li>
</ul></li>
<li><p>The box in the lower right shows what‚Äôs typically in the frequentist toolbox ‚Äî <strong>œá¬≤ fitting</strong>, <strong>2PCF</strong>, and so on.</p></li>
</ul>
<p>‚ÄúThis pipeline is efficient and interpretable ‚Äî but as we‚Äôll see, it has limitations when you move beyond simple, low-dimensional, or linear models.‚Äù</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="inference-in-cosmology-the-bayesian-pipeline" class="slide level2" style="font-size: 20px;">
<h2>Inference in Cosmology: The Bayesian Pipeline</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><br></p>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/freq_pipeline_2.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_pipeline_0.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_pipeline_1.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_pipeline_2.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<div class="fragment fade-in" data-fragment-index="1">
<ul>
<li>Start from <strong>summary statistics</strong>: <span class="math inline">\(P(k)\)</span>, <span class="math inline">\(C_\ell\)</span> , 2PCF</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<ul>
<li>Sample from a <strong>Prior</strong> <span class="math inline">\(P(\Omega)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<ul>
<li>Compute <strong>likelihood</strong>: <span class="math inline">\(L(Obs \vert \Omega)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<ul>
<li>Sampler from the <strong>Posterior</strong> <span class="math inline">\(P(\Omega \vert Obs)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="6">
<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 20px;">
<p><strong>Bayesian Toolbox</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 18px;">
<ul>
<li>Priors encode beliefs: <span class="math inline">\(P(\Omega)\)</span><br>
</li>
<li>Hierarchical Bayesian Modeling (HBM)</li>
<li>Probabilistic programming (e.g., <strong>NumPyro</strong>)</li>
<li>Gradient-based samplers: <strong>HMC</strong>, <strong>NUTS</strong></li>
</ul>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Start by emphasizing that, like the frequentist pipeline, the Bayesian version also begins with summary statistics like power spectra. But instead of finding a best-fit point estimate, the Bayesian approach defines a <strong>probabilistic model</strong> over cosmological parameters.</p>
<p>Now show image 2:</p>
<ul>
<li>We sample from a <strong>prior</strong> over parameters, combine it with a <strong>likelihood</strong> based on the observed data, and use this to compute the <strong>posterior</strong>.</li>
<li>This posterior captures all uncertainty, correlations, and degeneracies.</li>
<li>The Bayesian toolbox lets us extend models easily ‚Äî hierarchical structure, latent fields, flexible priors ‚Äî and perform inference using modern tools like NumPyro and gradient-based samplers (e.g.&nbsp;NUTS, HMC).</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="inference-in-cosmology-the-bayesian-pipeline-1" class="slide level2" style="font-size: 18px;" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Inference in Cosmology: The Bayesian Pipeline</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_pipeline_latent.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div><div class="column" style="width:30%;">
<div class="fragment fade-in" data-fragment-index="1">
<ul>
<li><strong>Prior</strong>: Theory-driven assumptions <span class="math inline">\(P(\Omega)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<ul>
<li><strong>Latent variables</strong>: Hidden/unobserved <span class="math inline">\(z \sim P(z \mid \Omega)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<ul>
<li><strong>Likelihood</strong>: Generates observables <span class="math inline">\(P(\text{Obs} \mid \Omega, z)\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<ul>
<li><strong>Posterior</strong>: infer <span class="math inline">\(P(\Omega \mid \text{Obs})\)</span></li>
</ul>
</div>
</div></div>
</section>
<section id="inference-in-cosmology-the-bayesian-pipeline-2" class="slide level2" style="font-size: 18px;" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Inference in Cosmology: The Bayesian Pipeline</h2>
<div class="columns">
<div class="column" style="width:10%;">
<p><br></p>
<div class="quarto-figure quarto-figure-middle">
<figure>
<p><img data-src="assets/bayes/bayes_pipeline_latent.svg" class="quarto-figure quarto-figure-middle" style="width:100.0%"></p>
</figure>
</div>
</div><div class="column" style="width:90%;">
<p><strong>Bayes‚Äô Rule with all components:</strong></p>
<blockquote>
<p>Full decomposition of the posterior. The denominator marginalizes over all possible parameters.</p>
</blockquote>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<p><span class="math display">\[
\underbrace{P(\Omega \mid \text{Obs})}_{\text{Posterior}}
= \frac{
    \underbrace{P(\text{Obs} \mid \Omega)}_{\text{Likelihood}}
    \cdot
    \underbrace{P(\Omega)}_{\text{Prior}}
}{
    \underbrace{
        \int P(\text{Obs} \mid \Omega) P(\Omega) \, d\Omega
    }_{\text{Evidence}}
}
\]</span></p>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<p><span class="math display">\[
\underbrace{P(\Omega \mid \text{Obs})}_{\text{Posterior}}
= \frac{
    \underbrace{\int P(\text{Obs} \mid \Omega, z)\, P(z \mid \Omega)\, dz}_{\text{Likelihood (marginalized over latent $z$)}}
    \cdot
    \underbrace{P(\Omega)}_{\text{Prior}}
}{
    \underbrace{
        \int \left[ \int P(\text{Obs} \mid \Omega, z)\, P(z \mid \Omega)\, dz \right] P(\Omega)\, d\Omega
    }_{\text{Evidence}}
}
\]</span></p>
</div>
</div>
</div></div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="fragment fade-in" data-fragment-index="3">
<blockquote>
<p>In practice, we drop the evidence term when sampling ‚Äî it‚Äôs a constant.</p>
</blockquote>
<p><span class="math display">\[
P(\Omega \mid \text{Obs})
\propto
\underbrace{\int P(\text{Obs} \mid \Omega, z)\, P(z \mid \Omega) \, dz}_{\text{Marginal Likelihood}}
\cdot
\underbrace{P(\Omega)}_{\text{Prior}}
\]</span></p>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<p><span class="math display">\[
\log P(\Omega \mid \text{Obs})
= \log P(\text{Obs} \mid \Omega) + \log P(\Omega)
\]</span></p>
</div>
</div><div class="column" style="width:50%;">
<div class="fragment fade-in" data-fragment-index="5">
<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 17px;">
<p><strong>Bayes‚Äô Rule in Practice</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 15px;">
<ul>
<li><p>The <strong>posterior</strong> combines theory (prior) and data (likelihood) to infer cosmological parameters.</p></li>
<li><p><strong>Latent variables</strong> <span class="math inline">\(z\)</span> encode hidden structure (e.g., initial fields, nuisance parameters).</p></li>
<li><p>The <strong>evidence</strong> is often ignored during sampling (it‚Äôs constant).</p></li>
<li><p><strong>Model comparison</strong> via the Bayes Factor:</p>
<p><span class="math display">\[
\text{Bayes Factor} = \frac{P(\text{Obs} \mid \mathcal{M}_1)}{P(\text{Obs} \mid \mathcal{M}_2)}
\]</span></p></li>
</ul>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes for This Sequence:</strong></p>
<hr>
<p><strong>STEP 1:</strong></p>
<p>We now extend the Bayesian pipeline by introducing <strong>latent variables</strong> ‚Äî denoted <em>z</em>. These are hidden, unobserved quantities such as initial conditions, noise fields, or instrumental effects.</p>
<ul>
<li><p>The <strong>prior</strong> encodes our belief over cosmological parameters Œ©. It‚Äôs <strong>unobserved</strong>, <strong>unknown</strong>, and is the <strong>target of inference</strong>.</p></li>
<li><p>The <strong>latent variables</strong> <em>z</em> are also <strong>unobserved</strong> and <strong>unknown</strong>, but they are <strong>conditional on the prior</strong> ‚Äî they depend on Œ© and are integrated out (marginalized) during inference.</p></li>
<li><p>The <strong>likelihood</strong> is a forward model that generates observables given both the prior and latent structure: <span class="math inline">\(\mathcal{L}(\text{Obs} \mid \Omega, z)\)</span></p></li>
<li><p>The <strong>posterior</strong> combines all of these: it tells us how probable different cosmological parameters are, given the data and the model structure: <span class="math inline">\(P(\Omega \mid \text{Obs}) \propto \int \mathcal{L}(\text{Obs} \mid \Omega, z) \, P(z \mid \Omega) \, dz \cdot P(\Omega)\)</span></p></li>
</ul>
<p>This hierarchical view is what powers modern cosmological inference.</p>
<p><strong>STEP 2:</strong></p>
<p>Here‚Äôs a polished version of your speaker notes for that section:</p>
<hr>
<p>We now move to the full <strong>Bayesian formula</strong> ‚Äî starting without latent variables:</p>
<p>This gives us the <strong>posterior</strong> as the product of the <strong>likelihood</strong> and the <strong>prior</strong>, normalized by the <strong>evidence</strong>. The evidence <span class="math inline">\(P(\text{Obs})\)</span> ensures the posterior is a proper probability distribution.</p>
<p>Now, when we introduce <strong>latent variables</strong> <span class="math inline">\(z\)</span>, the likelihood itself becomes an integral over those:</p>
<p>This marginal likelihood accounts for the full hidden structure.</p>
<p>In practice, we <strong>ignore the evidence</strong> term when sampling:</p>
<ul>
<li>It‚Äôs <strong>constant for a given model</strong> ‚Äî so it doesn‚Äôt affect posterior shape.</li>
<li>It‚Äôs <strong>computationally expensive</strong> to compute (requires full integration).</li>
<li>But: it‚Äôs <strong>very useful for comparing models</strong>.</li>
</ul>
<hr>
<p><strong>Summary</strong>:</p>
<ul>
<li>We sample directly from the <strong>posterior</strong>, which combines <strong>prior</strong> and <strong>likelihood</strong>.</li>
<li><strong>Latent variables</strong> model hidden or uncertain structure ‚Äî like initial conditions.</li>
<li>The <strong>evidence</strong> is dropped during sampling, but becomes important in <strong>model comparison</strong> using the <strong>Bayes Factor</strong>:</li>
</ul>
<p>This tells us which model is better supported by the data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="two-roads-to-inference-frequentist-and-bayesian" class="slide level2" style="font-size: 20px;">
<h2>Two Roads to Inference: Frequentist and Bayesian</h2>
<p><img data-src="assets/bayes/freq_vs_bayes.png" class="absolute" style="top: -50px; left: 900px; width: 20%; "></p>

<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 20px;">
<p><strong>Conceptual Differences</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 18px;">
<table class="caption-top">
<colgroup>
<col style="width: 14%">
<col style="width: 43%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Concept</strong></th>
<th><strong>Frequentist</strong></th>
<th><strong>Bayesian</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Parameters</strong></td>
<td><strong>Fixed</strong> but unknown</td>
<td><strong>Random variables</strong> with a prior</td>
</tr>
<tr class="even">
<td><strong>Goal</strong></td>
<td><strong>Point estimate</strong> (e.g.&nbsp;MLE)</td>
<td><strong>Full distribution</strong> (posterior over parameters)</td>
</tr>
<tr class="odd">
<td><strong>Uncertainty</strong></td>
<td>From <strong>data variability</strong></td>
<td>From <strong>parameter uncertainty</strong> (posterior)</td>
</tr>
<tr class="even">
<td><strong>Prior Knowledge</strong></td>
<td><strong>Not used</strong></td>
<td><strong>Explicitly included</strong> via prior <span class="math inline">\(P(\Omega)\)</span></td>
</tr>
<tr class="odd">
<td><strong>Interval Meaning</strong></td>
<td><strong>Confidence interval</strong>: ‚Äú95% of experiments contain truth‚Äù</td>
<td><strong>Credible interval</strong>: ‚Äú95% chance truth is in this range‚Äù</td>
</tr>
<tr class="even">
<td><strong>Likelihood Role</strong></td>
<td>Central in <strong><span class="math inline">\(\chi^2\)</span> minimization</strong>, fits</td>
<td>Combined with <strong>prior</strong> to form posterior</td>
</tr>
<tr class="odd">
<td><strong>Inference Output</strong></td>
<td><strong>Best-fit estimate</strong> + error bars</td>
<td><strong>Posterior distribution</strong></td>
</tr>
<tr class="even">
<td><strong>Tooling</strong></td>
<td><strong>Optimization</strong> (e.g.&nbsp;œá¬≤, maximum likelihood)</td>
<td><strong>Sampling</strong> (e.g.&nbsp;MCMC, HMC, NUTS)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="columns">
<div class="column" style="width:90%;">
<p>Although these approaches are often contrasted, <strong>they‚Äôre not mutually exclusive</strong>. Modern workflows ‚Äî like <strong>causal inference</strong> in <a href="https://www.youtube.com/watch?v=FdnMWdICdRs"><em>Statistical Rethinking</em></a> ‚Äî draw on both perspectives. Bayesian methods offer a formal way to <strong>combine theory and data</strong>, especially powerful when simulations are involved.</p>
</div><div class="column" style="width:10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/stat_rethink.jpg" style="width:100.0%"></p>
<figcaption>Statistical Rethinking</figcaption>
</figure>
</div>
</div></div>
<p><br></p>
<aside class="notes">
<p>This slide lays out a direct comparison between the <strong>frequentist</strong> and <strong>Bayesian</strong> approaches.</p>
<p>We‚Äôre highlighting not just the philosophical differences, but also the <strong>practical consequences</strong>.</p>
<p>A few key contrasts to emphasize:</p>
<ul>
<li><p><strong>Parameters</strong>: In frequentist stats, parameters are fixed but unknown. In Bayesian stats, they‚Äôre <strong>random variables</strong> ‚Äî we assign distributions to represent our uncertainty.</p></li>
<li><p><strong>Goal</strong>: Frequentists usually aim for a <strong>point estimate</strong> (like the MLE). Bayesians aim to recover the <strong>entire posterior distribution</strong>.</p></li>
<li><p><strong>Uncertainty</strong>: Frequentists focus on <strong>data variability</strong> ‚Äî uncertainty from random samples. Bayesians focus on <strong>parameter uncertainty</strong> ‚Äî how uncertain we are about the parameters given the data.</p></li>
<li><p><strong>Intervals</strong>: The interpretations are totally different. A frequentist says, ‚Äú95% of the time, this interval contains the truth.‚Äù A Bayesian says, ‚ÄúThere‚Äôs a 95% chance the truth is in this interval.‚Äù</p></li>
<li><p><strong>Tooling</strong>: Optimization vs.&nbsp;sampling. Frequentists often rely on <strong>curve fitting</strong>, minimization, etc. Bayesian workflows rely on <strong>sampling</strong> (MCMC, HMC, NUTS).</p></li>
</ul>
<p>Make sure the audience sees this isn‚Äôt about choosing sides. As the bottom note says ‚Äî they‚Äôre <strong>not mutually exclusive</strong>. A lot of modern workflows combine both perspectives.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="image">@image</span> credit:Wayne Stewart</p>
</div></aside></section></section>
<section>
<section id="the-mechanics-of-inference" class="title-slide slide level1 center">
<h1>üõ†Ô∏è The Mechanics of Inference</h1>

</section>
<section id="sampling-the-posterior-the-core-loop" class="slide level2" style="font-size: 20px;">
<h2>Sampling the Posterior: The Core Loop</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/inference_loop.svg" class="quarto-figure quarto-figure-center" style="width:75.0%"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<p><strong>The Sampling Loop:</strong></p>
<div class="fragment fade-in" data-fragment-index="1">
<ul>
<li>Start from a sample <span class="math inline">\((\Omega^t, z^t)\)</span><br>
</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<ul>
<li>Propose new sample <span class="math inline">\((\Omega', z')\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<ul>
<li>Compute <strong>acceptance probability</strong></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<ul>
<li>Accept or reject proposal</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="5">
<ul>
<li>Repeat and store accepted samples ‚ü∂ <strong>posterior</strong></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="6">
<p><strong>Goal:</strong> Explore the full shape of the posterior<br>
(even in high-dim, non-Gaussian spaces)</p>
</div>
<div class="fragment fade-in" data-fragment-index="7">
<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 20px;">
<p><strong>Key Takeaways</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 18px;">
<ul>
<li>Most samplers follow this <strong>accept/reject loop</strong></li>
<li>Differ by how they propose samples: ‚Äì Random walk (e.g., MH) ‚Äì Gradient-guided (e.g., HMC, NUTS)</li>
<li>Some skip rejection (e.g., Langevin, VI)</li>
</ul>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>This slide illustrates the core mechanism behind most MCMC samplers ‚Äî the accept/reject loop.</p>
<p>We start with a current sample from the posterior, say <span class="math inline">\((\Omega^t, z^t)\)</span>. The sampler then proposes a new point <span class="math inline">\((\Omega', z')\)</span>, using some rule ‚Äî it might be a random walk, or it might use gradients like in HMC or NUTS.</p>
<p>Next, we compute the <strong>acceptance probability</strong> ‚Äî this depends on how likely the new sample is under the posterior compared to the current one.</p>
<p>Then we make a decision:</p>
<ul>
<li>If the new sample is more likely (or meets some acceptance threshold), we accept it and add it to the chain.</li>
<li>If not, we reject it and store the current one again.</li>
</ul>
<p>This process repeats to build a chain of samples. The accepted ones collectively approximate the posterior distribution.</p>
<p>On the right, the key takeaways:</p>
<ul>
<li>Most samplers use this loop.</li>
<li>The difference lies in how they generate proposals ‚Äî basic methods use random walks, while advanced methods use gradients.</li>
<li>Some newer algorithms avoid rejection altogether ‚Äî like variational inference or some Langevin-based flows ‚Äî but the classic accept/reject structure remains fundamental to many MCMC approaches.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 style="font-size: 20px;" id="sampling-algorithms-at-a-glance">Sampling Algorithms at a Glance</h3>
<div class="columns">
<div class="column" style="width:65%;">
<div class="fragment fade-in" data-fragment-index="1">
<p><strong>Metropolis-Hastings (MCMC)</strong></p>
<ul>
<li><p><strong>Propose</strong>: Random walk <span class="math inline">\(\Omega' \sim \mathcal{N}(\Omega^t, \sigma^2)\)</span></p></li>
<li><p><strong>Accept</strong>:</p>
<p><span class="math display">\[
\alpha = \min\left(1, \frac{P(\text{Obs} \mid \Omega') P(\Omega')}{P(\text{Obs} \mid \Omega^t) P(\Omega^t)}\right)
\]</span></p></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<p><strong>Hamiltonian Monte Carlo (HMC)</strong></p>
<ul>
<li><strong>Propose</strong>: Simulate physics Trajectory via gradients <span class="math inline">\(\nabla\_\Omega \log P(\text{Obs} \mid \Omega)\)</span></li>
<li><strong>Accept</strong>: Based on Hamiltonian energy conservation. <span class="math inline">\(\alpha = \min(1, e^{\mathcal{H}(\Omega^t, p^t) - \mathcal{H}(\Omega', p')})\)</span></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<p><strong>NUTS (No-U-Turn Sampler)</strong> Same as HMC, but auto-tunes:</p>
<ul>
<li>Step size</li>
<li>Trajectory length (stops before looping back)</li>
</ul>
</div>
</div><div class="column" style="width:35%;">
<div class="fragment fade-in" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/MCMC.gif" class="quarto-figure quarto-figure-center" style="border: 2px solid black; padding: 2px;;width:80.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/HMC.gif" class="quarto-figure quarto-figure-center" style="border: 2px solid black; padding: 2px;;width:80.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/NUTS.gif" class="quarto-figure quarto-figure-center" style="border: 2px solid black; padding: 2px;;width:80.0%"></p>
</figure>
</div>
</div>
</div></div>
<p><br> <br></p>

<aside class="notes">
<p>This slide gives a quick overview of three core MCMC algorithms.</p>
<p>We start with <strong>Metropolis-Hastings (MH)</strong>: It proposes a new sample using a simple random walk ‚Äî typically from a Normal centered on the current value. The acceptance probability is the ratio of posteriors ‚Äî new over old ‚Äî and we accept based on how much better the new sample fits. You can see on the diagram: it just takes a small step and checks whether to keep it.</p>
<p>Next, <strong>Hamiltonian Monte Carlo (HMC)</strong>: Rather than proposing random jumps, HMC uses gradients to simulate a physical trajectory through parameter space ‚Äî like a particle rolling through a potential landscape. This allows it to make larger moves that still preserve the posterior distribution. Acceptance here is based on energy conservation, using a Hamiltonian formulation.</p>
<p>Finally, <strong>NUTS (No-U-Turn Sampler)</strong>: This builds on HMC, but it adds smart tuning:</p>
<ul>
<li>It automatically adjusts step size</li>
<li>It stops the trajectory before looping back on itself ‚Äî hence ‚ÄúNo-U-Turn‚Äù This makes NUTS a great default sampler in most PPLs ‚Äî it avoids a lot of manual tuning and works well out of the box.</li>
</ul>
<p>Together, these illustrate a spectrum: from simple MH to advanced gradient-based samplers ‚Äî and show how modern samplers make use of geometry to efficiently explore high-dimensional spaces.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="credit">@credit</span>: https://github.com/chi-feng/mcmc-demo</p>
</div></aside></section>
<section id="gradient-based-sampling-in-action" class="slide level2" style="font-size: 20px;" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Gradient-Based Sampling in Action</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/gaussian_hmc.gif" style="width:50.0%"></p>
<figcaption>HMC: Gaussian Posterior</figcaption>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/gaussian_hmc_density.png" style="width:50.0%"></p>
<figcaption>HMC: Gaussian Posterior</figcaption>
</figure>
</div>
</div>
</div>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/banana_hmc.gif" style="width:50.0%"></p>
<figcaption>HMC: Banana Posterior</figcaption>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/banana_hmc_density.png" style="width:50.0%"></p>
<figcaption>HMC: Banana Posterior</figcaption>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/gaussian_mcmc.gif" style="width:50.0%"></p>
<figcaption>MCMC: Gaussian Posterior</figcaption>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/gaussian_mcmc_density.png" style="width:50.0%"></p>
<figcaption>MCMC: Gaussian Posterior</figcaption>
</figure>
</div>
</div>
</div>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/banana_mcmc.gif" style="width:50.0%"></p>
<figcaption>MCMC: Banana Posterior</figcaption>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/banana_mcmc_density.png" style="width:50.0%"></p>
<figcaption>MCMC: Banana Posterior</figcaption>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="gradient-based-sampling-in-action-1" class="slide level2" style="font-size: 20px;" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Gradient-Based Sampling in Action</h2>
<div class="columns">
<div class="column" style="width:10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/gaussian_hmc_density.png" style="width:50.0%"></p>
<figcaption>HMC: Gaussian Posterior</figcaption>
</figure>
</div>
</div><div class="column" style="width:10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/banana_hmc_density.png" style="width:50.0%"></p>
<figcaption>HMC: Banana Posterior</figcaption>
</figure>
</div>
</div><div class="column" style="width:10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/gaussian_mcmc_density.png" style="width:50.0%"></p>
<figcaption>MCMC: Gaussian Posterior</figcaption>
</figure>
</div>
</div><div class="column" style="width:10%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/banana_mcmc_density.png" style="width:50.0%"></p>
<figcaption>MCMC: Banana Posterior</figcaption>
</figure>
</div>
</div><div class="column" style="width:60%;">
<ul>
<li>In high dimensions, <strong>random walk proposals</strong> (MCMC) often land in low-probability regions ‚ü∂ low acceptance.</li>
<li>To maintain acceptance, step size must shrink like <strong><span class="math inline">\(1/\sqrt{d}\)</span></strong> ‚ü∂ very slow exploration.</li>
<li><strong>HMC uses gradients</strong> to follow high-probability paths ‚ü∂ <strong>better samples, fewer steps</strong>.</li>
</ul>
</div></div>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/samples_only.png" style="width:50.0%"></p>
<figcaption>Sampling Without Gradients</figcaption>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Samplers/samples_with_gradients.png" style="width:50.0%"></p>
<figcaption>Sampling With Gradients</figcaption>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>In this slide we compare HMC and traditional MCMC in two scenarios:</p>
<hr>
<h3 id="top-row-gaussian-posterior">Top row: <strong>Gaussian posterior</strong></h3>
<ul>
<li>HMC (left) aligns well with the true density contours ‚Äî samples are well spread.</li>
<li>MCMC (right) struggles a bit ‚Äî it‚Äôs noisy, slightly distorted, and shows <strong>correlated samples</strong>.</li>
<li>That‚Äôs because MCMC does a random walk, which is inefficient even in simple geometries.</li>
</ul>
<hr>
<h3 id="bottom-row-banana-shaped-posterior">Bottom row: <strong>Banana-shaped posterior</strong></h3>
<ul>
<li>This is a <strong>nonlinear</strong>, curved posterior ‚Äî a much harder target.</li>
<li>HMC (left) still tracks the true shape well using its gradient information.</li>
<li>MCMC (right) again struggles: it oversamples in wrong regions and can‚Äôt explore the full space.</li>
</ul>
<hr>
<h3 id="key-point">Key Point:</h3>
<p>HMC shines when the geometry is tricky. Its gradients guide proposals along the posterior, unlike MCMC‚Äôs aimless wandering.</p>
<p>This motivates why we use HMC or NUTS in high-dimensional, curved, or strongly correlated problems ‚Äî like cosmology.</p>
<p><strong>Slide: Sampling Without Gradients</strong></p>
<ul>
<li>This shows how traditional MCMC struggles when sampling from complex distributions.</li>
<li>Here, proposals are based on <strong>random walks</strong>, which means they can easily jump into low-probability regions.</li>
<li>As a result, many proposals are rejected ‚Äî leading to inefficient sampling.</li>
<li>To maintain high acceptance, samplers reduce step size ‚Äî but this slows down exploration dramatically, especially in high dimensions.</li>
<li>You can see the samples (blue dots) under-sample the second peak and have poor coverage overall.</li>
</ul>
<hr>
<p><strong>Slide: Sampling With Gradients</strong></p>
<ul>
<li>Now we add <strong>gradient information</strong> ‚Äî this is what HMC uses.</li>
<li>Gradients give the sampler a sense of ‚Äúdirection,‚Äù pointing it toward high-probability areas.</li>
<li>Instead of random jumps, we simulate <strong>trajectories</strong> that follow the shape of the distribution.</li>
<li>This enables much better exploration with fewer steps.</li>
<li>As a result, samples land more effectively across both peaks and better represent the target distribution.</li>
<li>This illustrates why gradient-based samplers like HMC or NUTS perform so well in high-dimensional, structured problems.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="differentiable-inference-with-jax" class="slide level2" style="font-size: 20px;">
<h2>Differentiable Inference with JAX</h2>
<p>When it comes to <strong>gradients</strong>, always think of <strong>JAX</strong>.</p>
<p><br></p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>An Easy pythonic API</strong></p>
<div class="sourceCode" id="cb1" data-code-line-numbers="|11"><pre class="sourceCode numberSource Python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> jax</span>
<span id="cb1-2"><a></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb1-3"><a></a><span class="im">from</span> jax <span class="im">import</span> random</span>
<span id="cb1-4"><a></a></span>
<span id="cb1-5"><a></a><span class="kw">def</span> sample_prior(key):</span>
<span id="cb1-6"><a></a>    <span class="cf">return</span> random.normal(key, shape<span class="op">=</span>(<span class="dv">3</span>,))  <span class="co"># Œ© ~ N(0, 1)</span></span>
<span id="cb1-7"><a></a></span>
<span id="cb1-8"><a></a><span class="kw">def</span> log_prob(omega):</span>
<span id="cb1-9"><a></a>    <span class="cf">return</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> jnp.<span class="bu">sum</span>(omega<span class="op">**</span><span class="dv">2</span>)  <span class="co"># log p(Œ©) ‚àù -Œ©¬≤</span></span>
<span id="cb1-10"><a></a></span>
<span id="cb1-11"><a></a>log_prob_jit <span class="op">=</span> jax.jit(log_prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="fragment fade-in" data-fragment-index="2">
<p><strong>Easily accessible gradients using GRAD</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>omegas <span class="op">=</span> ... <span class="co"># Sampled Œ©</span></span>
<span id="cb2-2"><a></a>gradients <span class="op">=</span> jax.grad(log_prob_jit)(omegas)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<p><strong>Supports vectorization using VMAP</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="kw">def</span> generate_samples(seeds):</span>
<span id="cb3-2"><a></a>    key <span class="op">=</span> jax.random.PRNGKey(seeds)</span>
<span id="cb3-3"><a></a>    omega <span class="op">=</span> sample_prior(key)</span>
<span id="cb3-4"><a></a>    <span class="cf">return</span> omega</span>
<span id="cb3-5"><a></a>seeds <span class="op">=</span> jnp.arange(<span class="dv">0</span>, <span class="dv">1000</span>)</span>
<span id="cb3-6"><a></a>omegas <span class="op">=</span> jax.vmap(generate_samples)(seeds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/Logos/JaxLogo.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
</div></div>
<aside class="notes">
<ul>
<li>This is why JAX is such a natural fit for inference: it‚Äôs fully differentiable and built around <strong>gradients</strong>.</li>
<li>On the left we show three core ideas that power modern inference.</li>
</ul>
<p><strong>First block</strong>: JAX gives you a familiar NumPy-like API, with tools like <code>jit</code> to compile and optimize code. You define a prior, a log-prob function, and wrap it in <code>jit</code> ‚Äî easy and fast.</p>
<p><strong>Second block</strong>: With <code>jax.grad</code>, you can differentiate any function. That means you get gradients of the log-posterior ‚Äúfor free,‚Äù which is exactly what HMC or variational inference need.</p>
<p><strong>Third block</strong>: JAX scales easily ‚Äî use <code>vmap</code> to vectorize your function across many seeds, particles, or chains. This is a huge win when doing amortized inference or simulation-based methods.</p>
<ul>
<li>Altogether, JAX provides the <strong>gradient plumbing</strong> for probabilistic inference ‚Äî while remaining readable and fast.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="practical-bayesian-modeling-inference-with-jax" class="title-slide slide level1 center">
<h1>Practical Bayesian Modeling &amp; Inference with JAX</h1>

</section>
<section id="a-recipe-for-bayesian-inference" class="slide level2">
<h2>A Recipe for Bayesian Inference</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="fragment fade-in" data-fragment-index="2">
<p><strong>1. Probabilistic Programming Language (PPL)</strong> <em>NumPyro</em>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="im">import</span> numpyro</span>
<span id="cb4-2"><a></a><span class="im">import</span> numpyro.distributions <span class="im">as</span> dist</span>
<span id="cb4-3"><a></a></span>
<span id="cb4-4"><a></a><span class="kw">def</span> model():</span>
<span id="cb4-5"><a></a>    omega_m <span class="op">=</span> numpyro.sample(<span class="st">"Œ©‚Çò"</span>, dist.Uniform(<span class="fl">0.1</span>, <span class="fl">0.5</span>))</span>
<span id="cb4-6"><a></a>    sigma8 <span class="op">=</span> numpyro.sample(<span class="st">"œÉ‚Çà"</span>, dist.Normal(<span class="fl">0.8</span>, <span class="fl">0.1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<p><strong>2. Computing Likelihoods</strong> <em>JAX-Cosmo</em>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="im">import</span> jax_cosmo <span class="im">as</span> jc</span>
<span id="cb5-2"><a></a><span class="kw">def</span> likelihood(cosmo_params):</span>
<span id="cb5-3"><a></a>    mu, cov <span class="op">=</span> jc.angular_cl.gaussian_cl_covariance_and_mean(</span>
<span id="cb5-4"><a></a>        cosmo_params, ell, probes</span>
<span id="cb5-5"><a></a>    )</span>
<span id="cb5-6"><a></a>    <span class="cf">return</span> jc.likelihood.gaussian_log_likelihood(data, mu, cov)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<p><strong>3. Sampling the Posterior</strong> <em>NumPyro &amp; Blackjax</em>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">from</span> numpyro.infer <span class="im">import</span> MCMC, NUTS</span>
<span id="cb6-2"><a></a></span>
<span id="cb6-3"><a></a>kernel <span class="op">=</span> NUTS(model)</span>
<span id="cb6-4"><a></a>mcmc <span class="op">=</span> MCMC(kernel, num_warmup<span class="op">=</span><span class="dv">500</span>, num_samples<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb6-5"><a></a>mcmc.run(random.PRNGKey(<span class="dv">0</span>))</span>
<span id="cb6-6"><a></a>samples <span class="op">=</span> mcmc.get_samples()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="5">
<p><strong>4. Visualizing the Posterior</strong> <em>ArviZ</em>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb7-2"><a></a>samples <span class="op">=</span> mcmc.get_samples()</span>
<span id="cb7-3"><a></a>az.plot_pair(samples, marginals<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div><div class="column" style="width:40%;">
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/shopping_cart_0.svg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/shopping_cart_1.svg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/shopping_cart_2.svg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/shopping_cart_3.svg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="5">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/shopping_cart_4.svg" class="quarto-figure quarto-figure-center" style="width:40.0%"></p>
</figure>
</div>
</div>
</div>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_full.svg" class="quarto-figure quarto-figure-center" style="width:70.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="2">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_prior.svg" class="quarto-figure quarto-figure-center" style="width:70.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="3">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_likelihood.svg" class="quarto-figure quarto-figure-center" style="width:70.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_sample.svg" class="quarto-figure quarto-figure-center" style="width:70.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="5">
<img data-src="assets/bayes/post_corner.png" class="quarto-figure quarto-figure-center" style="width:70.0%">
<div style="text-align: center; font-size: 12px;">
<span class="citation" data-cites="credit">@credit</span>: Zeghal et al.&nbsp;(2409.17975)
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Here are the speaker notes for the two slides:</p>
<hr>
<p><strong>Slide 1: ‚ÄúA Recipe for Bayesian Inference‚Äù</strong></p>
<ul>
<li><p>Now let‚Äôs break Bayesian inference into a practical workflow.</p></li>
<li><p>First, we define our model using a <strong>probabilistic programming language</strong> ‚Äî here, NumPyro. This is where we encode the prior and the structure of the model.</p></li>
<li><p>Second, we use a tool like <strong>JAX-Cosmo</strong> to compute the likelihood. This connects cosmological parameters to observable predictions ‚Äî such as angular power spectra.</p></li>
<li><p>Third, we use <strong>MCMC</strong> or <strong>BlackJAX</strong> to sample from the posterior.</p>
<ul>
<li>This is where sampling happens, and where gradient-based methods like NUTS come into play.</li>
</ul></li>
<li><p>Finally, we extract posterior samples to analyze uncertainty and parameter correlations.</p></li>
</ul>
<p>The graphic on the right summarizes this logic visually: from prior ‚Üí likelihood ‚Üí posterior ‚Üí sample.</p>
<hr>
<p><strong>Slide 2: ‚ÄúA Recipe for Bayesian Inference (Full Loop)‚Äù</strong></p>
<ul>
<li>This slide extends the recipe with the <strong>final step: visualization</strong>.</li>
<li>After sampling, we can summarize and visualize the posterior with tools like <strong>ArviZ</strong>.</li>
<li>The corner plot on the right shows the joint and marginal distributions ‚Äî a key diagnostic to assess whether inference worked and how parameters are correlated.</li>
<li>The dashed vs.&nbsp;solid lines show different inference strategies ‚Äî possibly <strong>explicit</strong> (forward simulations) vs <strong>implicit</strong> likelihoods.</li>
</ul>
<p>The takeaway is that with JAX, NumPyro, and JAX-Cosmo, we have a <strong>modular pipeline</strong> for Bayesian inference ‚Äî from model definition to visual diagnostics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="a-minimal-bayesian-linear-model" class="slide level2" style="font-size: 18px;">
<h2>A Minimal Bayesian Linear Model</h2>
<p><strong>Define a simple linear model:</strong></p>
<div class="sourceCode" id="cb8" data-code-line-numbers="|1-8|10-16"><pre class="sourceCode numberSource Python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>true_w <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb8-2"><a></a>true_b <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb8-3"><a></a>num_points <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb8-4"><a></a></span>
<span id="cb8-5"><a></a>rng_key <span class="op">=</span> jax.random.PRNGKey(<span class="dv">0</span>)</span>
<span id="cb8-6"><a></a>x_data <span class="op">=</span> jnp.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, num_points)</span>
<span id="cb8-7"><a></a>noise <span class="op">=</span> jax.random.normal(rng_key, shape<span class="op">=</span>(num_points,)) <span class="op">*</span> <span class="fl">0.3</span></span>
<span id="cb8-8"><a></a>y_data <span class="op">=</span> true_w <span class="op">*</span> x_data <span class="op">+</span> true_b <span class="op">+</span> noise</span>
<span id="cb8-9"><a></a></span>
<span id="cb8-10"><a></a><span class="kw">def</span> linear_regression(x, y<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-11"><a></a>    w <span class="op">=</span> numpyro.sample(<span class="st">"w"</span>, dist.Normal(<span class="fl">1.</span>, <span class="fl">2.</span>))</span>
<span id="cb8-12"><a></a>    b <span class="op">=</span> numpyro.sample(<span class="st">"b"</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">2.</span>))  <span class="co"># Fixed the second parameter</span></span>
<span id="cb8-13"><a></a>    sigma <span class="op">=</span> numpyro.sample(<span class="st">"sigma"</span>, dist.Exponential(<span class="fl">1.0</span>))</span>
<span id="cb8-14"><a></a></span>
<span id="cb8-15"><a></a>    mean <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b</span>
<span id="cb8-16"><a></a>    numpyro.sample(<span class="st">"obs"</span>, dist.Normal(mean, sigma), obs<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="fragment fade-in" data-fragment-index="1">
<p><strong>Run the model using NUTS:</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>kernel <span class="op">=</span> numpyro.infer.NUTS(linear_regression)</span>
<span id="cb9-2"><a></a>mcmc <span class="op">=</span> numpyro.infer.MCMC(kernel, num_warmup<span class="op">=</span><span class="dv">500</span>, num_samples<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb9-3"><a></a>mcmc.run(rng_key, x<span class="op">=</span>x_data, y<span class="op">=</span>y_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<p><strong>Posterior corner plot using arviz + corner</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>idata <span class="op">=</span> az.from_numpyro(mcmc)</span>
<span id="cb10-2"><a></a>posterior_array <span class="op">=</span> az.extract(idata, var_names<span class="op">=</span>[<span class="st">"w"</span>, <span class="st">"b"</span>, <span class="st">"sigma"</span>]).to_array().values.T</span>
<span id="cb10-3"><a></a></span>
<span id="cb10-4"><a></a>fig <span class="op">=</span> corner.corner(</span>
<span id="cb10-5"><a></a>    posterior_array,</span>
<span id="cb10-6"><a></a>    labels<span class="op">=</span>[<span class="st">"w"</span>, <span class="st">"b"</span>, <span class="st">"œÉ"</span>],</span>
<span id="cb10-7"><a></a>    truths<span class="op">=</span>[true_w, true_b, <span class="va">None</span>],</span>
<span id="cb10-8"><a></a>    show_titles<span class="op">=</span><span class="va">True</span></span>
<span id="cb10-9"><a></a>)</span>
<span id="cb10-10"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<p>This slide walks through the first notebook exercise ‚Äî a minimal Bayesian linear regression model using NumPyro.</p>
<ul>
<li>First block defines synthetic data: we‚Äôre sampling noisy <code>y</code> values from a true line <code>y = 2x - 1</code>.</li>
<li>The <code>linear_regression</code> function defines a probabilistic model: priors on slope <code>w</code>, intercept <code>b</code>, and noise <code>sigma</code>.</li>
<li>We use NUTS from NumPyro to sample from the posterior ‚Äî no likelihood math needed manually.</li>
<li>Finally, the bottom cell visualizes the posterior using <code>corner.py</code> and ArviZ. You‚Äôll see how the true parameters compare to the inferred distributions.</li>
</ul>
<p>This is the foundation ‚Äî you‚Äôll implement and modify this directly during the hands-on.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<h3 id="numpyro-tips-tricks-for-bayesian-modeling">Numpyro: Tips &amp; Tricks for Bayesian Modeling</h3>
<p><strong><code>numpyro.handlers.seed</code>: Fix randomness for reproducibility</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="im">from</span> numpyro.handlers <span class="im">import</span> seed</span>
<span id="cb11-2"><a></a>seeded_model <span class="op">=</span> seed(model, rng_key)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong><code>numpyro.handlers.trace</code>: Inspect internal execution and sample sites</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a><span class="im">from</span> numpyro.handlers <span class="im">import</span> trace</span>
<span id="cb12-2"><a></a>tr <span class="op">=</span> trace(model).get_trace()</span>
<span id="cb12-3"><a></a><span class="bu">print</span>(tr[<span class="st">"omega"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong><code>numpyro.handlers.condition</code>: Clamp a variable to observed or fixed value</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="im">from</span> numpyro.handlers <span class="im">import</span> condition</span>
<span id="cb13-2"><a></a>conditioned_model <span class="op">=</span> condition(model, data<span class="op">=</span>{<span class="st">"omega"</span>: <span class="fl">0.3</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong><code>numpyro.handlers.substitute</code>: Replace variables with fixed values (e.g., MAP estimates)</strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a><span class="im">from</span> numpyro.handlers <span class="im">import</span> substitute</span>
<span id="cb14-2"><a></a>subbed_model <span class="op">=</span> substitute(model, data<span class="op">=</span>{<span class="st">"omega"</span>: <span class="fl">0.3</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong><code>numpyro.handlers.reparam</code>: Reparameterize a site to improve geometry</strong></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="im">from</span> numpyro.infer.reparam <span class="im">import</span> LocScaleReparam</span>
<span id="cb15-2"><a></a><span class="im">from</span> numpyro.handlers <span class="im">import</span> reparam</span>
<span id="cb15-3"><a></a></span>
<span id="cb15-4"><a></a>reparammed_model <span class="op">=</span> reparam(model, config<span class="op">=</span>{<span class="st">"z"</span>: LocScaleReparam()})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>This slide gives a quick preview of useful <code>numpyro.handlers</code> you‚Äôll see in the notebooks.</p>
<ul>
<li><strong><code>seed</code></strong> lets you fix randomness for reproducibility ‚Äî critical for testing or debugging.</li>
<li><strong><code>trace</code></strong> inspects your model‚Äôs internal execution and samples ‚Äî great for seeing what actually gets sampled.</li>
<li><strong><code>condition</code></strong> clamps a variable to a fixed value ‚Äî useful for simulating data from a known model.</li>
<li><strong><code>substitute</code></strong> is similar, but lets you plug in values like MAP estimates.</li>
<li><strong><code>reparam</code></strong> lets you reparameterize tricky sample sites to improve posterior geometry and sampling.</li>
</ul>
<p>We‚Äôll practice using all of these interactively in the notebooks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="using-blackjax-and-numpyro" class="slide level2" style="font-size: 18px;">
<h2>Using BlackJax and NumPyro</h2>
<blockquote>
<p>BlackJax is NOT a PPL, so you need to combine it with a PPL like NumPyro or PyMC.</p>
</blockquote>
<div class="fragment fade-in" data-fragment-index="1">
<p><strong>Initialize model and extract the log-probability function</strong></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>rng_key, init_key <span class="op">=</span> jax.random.split(rng_key)</span>
<span id="cb16-2"><a></a>init_params, potential_fn, <span class="op">*</span>_ <span class="op">=</span> initialize_model(</span>
<span id="cb16-3"><a></a>    init_key, model, model_args<span class="op">=</span>(x_data,), model_kwargs<span class="op">=</span>{<span class="st">"y"</span>: y_data}, dynamic_args<span class="op">=</span><span class="va">True</span></span>
<span id="cb16-4"><a></a>)</span>
<span id="cb16-5"><a></a></span>
<span id="cb16-6"><a></a>logdensity_fn <span class="op">=</span> <span class="kw">lambda</span> position: <span class="op">-</span>potential_fn(x_data, y<span class="op">=</span>y_data)(position)</span>
<span id="cb16-7"><a></a>initial_position <span class="op">=</span> init_params.z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<p><strong>Run warm-up to adapt step size and mass matrix using BlackJAX‚Äôs window adaptation</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a>num_warmup <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb17-2"><a></a>adapt <span class="op">=</span> blackjax.window_adaptation(blackjax.nuts, logdensity_fn, target_acceptance_rate<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb17-3"><a></a>rng_key, warmup_key <span class="op">=</span> jax.random.split(rng_key)</span>
<span id="cb17-4"><a></a>(last_state, parameters), _ <span class="op">=</span> adapt.run(warmup_key, initial_position, num_warmup)</span>
<span id="cb17-5"><a></a>kernel <span class="op">=</span> blackjax.nuts(logdensity_fn, <span class="op">**</span>parameters).step</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<p><strong>Run BlackJAX NUTS sampling using <code>lax.scan</code></strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a><span class="kw">def</span> run_blackjax_sampling(rng_key, state, kernel, num_samples<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb18-2"><a></a>    <span class="kw">def</span> one_step(state, key):</span>
<span id="cb18-3"><a></a>        state, info <span class="op">=</span> kernel(key, state)</span>
<span id="cb18-4"><a></a>        <span class="cf">return</span> state, state</span>
<span id="cb18-5"><a></a></span>
<span id="cb18-6"><a></a>    keys <span class="op">=</span> jax.random.split(rng_key, num_samples)</span>
<span id="cb18-7"><a></a>    _, samples <span class="op">=</span> jax.lax.scan(one_step, state, keys)</span>
<span id="cb18-8"><a></a>    <span class="cf">return</span> samples</span>
<span id="cb18-9"><a></a></span>
<span id="cb18-10"><a></a>samples <span class="op">=</span> run_blackjax_sampling(rng_key, last_state, kernel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<p><strong>Convert BlackJAX output to ArviZ InferenceData</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a>idata <span class="op">=</span> az.from_dict(posterior<span class="op">=</span>samples.position)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<p>This slide shows how to use BlackJAX for sampling when you already have a model defined in NumPyro.</p>
<ul>
<li>First, we extract the <strong>log-probability function</strong> from a NumPyro model using <code>initialize_model</code>. This lets us use BlackJAX with the same model.</li>
<li>We define a <code>logdensity_fn</code>, which BlackJAX expects ‚Äî it just wraps the potential function with a negative sign.</li>
<li>Next, we run <strong>adaptive warm-up</strong> with <code>blackjax.window_adaptation</code>. This tunes step size and mass matrix like NumPyro does.</li>
<li>Then, we sample using <code>blackjax.nuts</code> with a loop written using <code>jax.lax.scan</code> for speed and JIT compatibility.</li>
<li>Finally, we convert the raw samples to an ArviZ-friendly format with <code>az.from_dict</code>.</li>
</ul>
<p>Key point: BlackJAX is super fast and modular, but not a full PPL ‚Äî so you bring your own model definition.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="sampler-comparison-table" class="slide level2" style="font-size: 26px;">
<h2>Sampler Comparison Table</h2>
<div class="solutionbox">
<div class="solutionbox-body" style="font-size: 18px;">
<table class="caption-top">
<colgroup>
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 9%">
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 24%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Sampler</th>
<th>Library</th>
<th>Uses Gradient</th>
<th>Auto-Tuning</th>
<th>Rejection</th>
<th>Best For</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>MCMC (SA)</strong></td>
<td>NumPyro</td>
<td>‚ùå</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>Simple low-dim models</td>
<td>No gradients; slow mixing</td>
</tr>
<tr class="even">
<td><strong>HMC</strong></td>
<td>NumPyro / BlackJAX</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>High-dim continuous posteriors</td>
<td>Needs tuned step size &amp; trajectory</td>
</tr>
<tr class="odd">
<td><strong>NUTS</strong></td>
<td>NumPyro / BlackJAX</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>General-purpose inference</td>
<td>Adaptive HMC</td>
</tr>
<tr class="even">
<td><strong>MALA</strong></td>
<td>BlackJAX</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>Local proposals w/ gradients</td>
<td>Stochastic gradient steps</td>
</tr>
<tr class="odd">
<td><strong>MCLMC</strong></td>
<td>BlackJAX</td>
<td>‚úÖ</td>
<td>‚úÖ (via L)</td>
<td>‚ùå</td>
<td>Large latent spaces</td>
<td>Unadjusted Langevin dynamics</td>
</tr>
<tr class="even">
<td><strong>Adj. MCLMC</strong></td>
<td>BlackJAX</td>
<td>‚úÖ</td>
<td>Manual (L)</td>
<td>‚úÖ</td>
<td>Bias-controlled Langevin sampler</td>
<td>Includes MH step</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>For more information check Simons et al.&nbsp;(2025), <a href="https://arxiv.org/pdf/2504.20130">¬ß2.2.3, arXiv:2504.20130</a></p>
<aside class="notes">
<p><strong>Speaker Notes ‚Äì Sampler Comparison Table</strong></p>
<p>This table gives a high-level overview of common samplers available in NumPyro and BlackJAX, organized by key features.</p>
<ul>
<li><p><strong>MCMC (SA)</strong>: This is standard Metropolis-Hastings ‚Äî no gradients, no tuning, but it‚Äôs simple and useful for low-dimensional problems. Slow mixing is a drawback.</p></li>
<li><p><strong>HMC</strong>: Hamiltonian Monte Carlo improves mixing by using gradients to simulate physics-based trajectories. It requires tuning for step size and path length, so it‚Äôs more manual.</p></li>
<li><p><strong>NUTS</strong>: No-U-Turn Sampler is HMC with built-in auto-tuning. It adapts step size and path length during warm-up, making it the default choice for general-purpose inference in NumPyro and BlackJAX.</p></li>
<li><p><strong>MALA</strong>: Metropolis-Adjusted Langevin Algorithm uses gradients for local proposals. It‚Äôs a good middle ground ‚Äî cheaper than full HMC, but more efficient than MH.</p></li>
<li><p><strong>MCLMC</strong>: Stochastic Langevin dynamics with <strong>no rejection</strong> step. Useful in large latent spaces, often in simulator-based models, but biased due to lack of correction.</p></li>
<li><p><strong>Adjusted MCLMC</strong>: Same as MCLMC, but now with a Metropolis-Hastings correction step. This helps reduce bias, at the cost of a little more computation.</p></li>
</ul>
<p><strong>Main idea:</strong> Pick the right sampler based on:</p>
<ul>
<li>whether you can compute gradients</li>
<li>dimensionality of the posterior</li>
<li>whether you need auto-tuning or not</li>
<li>whether you want unbiased samples (with rejection) or not.</li>
</ul>
<p>Final note: This is a simplified summary. For real applications, benchmarking is always best.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="examples-bayesian-inference-for-cosmology" class="title-slide slide level1 center">
<h1>Examples: Bayesian Inference for Cosmology</h1>

</section>
<section id="power-spectrum-inference-with-jax-cosmo" class="slide level2" style="font-size: 18px;">
<h2>Power Spectrum Inference with jax-cosmo</h2>
<div class="fragment fade-in" data-fragment-index="1">
<h4 id="step-1-simulate-cosmological-data">Step 1: Simulate Cosmological Data</h4>
<p><strong>Define a fiducial cosmology to generate synthetic observations</strong></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a>fiducial_cosmo <span class="op">=</span> jc.Planck15()</span>
<span id="cb20-2"><a></a>ell <span class="op">=</span> jnp.logspace(<span class="dv">1</span>, <span class="dv">3</span>)  <span class="co"># Multipole range for power spectrum</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Set up two redshift bins for galaxy populations</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a>nz1 <span class="op">=</span> jc.redshift.smail_nz(<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">1.</span>)</span>
<span id="cb21-2"><a></a>nz2 <span class="op">=</span> jc.redshift.smail_nz(<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">0.5</span>)</span>
<span id="cb21-3"><a></a>nzs <span class="op">=</span> [nz1, nz2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Define observational probes: weak lensing and number counts</strong></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>probes <span class="op">=</span> [</span>
<span id="cb22-2"><a></a>    jc.probes.WeakLensing(nzs, sigma_e<span class="op">=</span><span class="fl">0.26</span>),</span>
<span id="cb22-3"><a></a>    jc.probes.NumberCounts(nzs, jc.bias.constant_linear_bias(<span class="fl">1.</span>))</span>
<span id="cb22-4"><a></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Generate synthetic data using the fiducial cosmology</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a>mu, cov <span class="op">=</span> jc.angular_cl.gaussian_cl_covariance_and_mean(fiducial_cosmo, ell, probes)</span>
<span id="cb23-2"><a></a>rng_key <span class="op">=</span> jax.random.PRNGKey(<span class="dv">0</span>)</span>
<span id="cb23-3"><a></a>noise <span class="op">=</span> jax.random.multivariate_normal(rng_key, jnp.zeros_like(mu), cov)</span>
<span id="cb23-4"><a></a>data <span class="op">=</span> mu <span class="op">+</span> noise  <span class="co"># Fake observations</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<h4 id="step-2-define-the-numpyro-model">Step 2: Define the NumPyro Model</h4>
<div class="sourceCode" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a><span class="co"># Define a NumPyro probabilistic model to infer cosmological parameters</span></span>
<span id="cb24-2"><a></a><span class="kw">def</span> model(data):</span>
<span id="cb24-3"><a></a>    Omega_c <span class="op">=</span> numpyro.sample(<span class="st">"Omega_c"</span>, dist.Uniform(<span class="fl">0.1</span>, <span class="fl">0.5</span>))</span>
<span id="cb24-4"><a></a>    sigma8 <span class="op">=</span> numpyro.sample(<span class="st">"sigma8"</span>, dist.Uniform(<span class="fl">0.6</span>, <span class="fl">1.0</span>))</span>
<span id="cb24-5"><a></a>    </span>
<span id="cb24-6"><a></a>    <span class="co"># Forward model: compute theoretical prediction given parameters</span></span>
<span id="cb24-7"><a></a>    cosmo <span class="op">=</span> jc.Planck15(Omega_c<span class="op">=</span>Omega_c, sigma8<span class="op">=</span>sigma8)</span>
<span id="cb24-8"><a></a>    mu, cov <span class="op">=</span> jc.angular_cl.gaussian_cl_covariance_and_mean(cosmo, ell, probes)</span>
<span id="cb24-9"><a></a>    </span>
<span id="cb24-10"><a></a>    <span class="co"># Likelihood: multivariate Gaussian over angular power spectra</span></span>
<span id="cb24-11"><a></a>    numpyro.sample(<span class="st">"obs"</span>, dist.MultivariateNormal(mu, cov), obs<span class="op">=</span>data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<p>This slide introduces a basic end-to-end inference workflow using <code>jax-cosmo</code> and <code>NumPyro</code>.</p>
<p><strong>Step 1: Simulate synthetic cosmological data</strong></p>
<ul>
<li>We start with a fiducial cosmology using <code>jc.Planck15()</code>.</li>
<li>Define a multipole range (<code>ell</code>) and two redshift distributions for tomographic bins.</li>
<li>Create weak lensing and number count probes.</li>
<li>Then, using the angular power spectrum mean and covariance from <code>jax_cosmo</code>, we generate mock observations by adding Gaussian noise.</li>
</ul>
<p><strong>Step 2: Define the NumPyro model</strong></p>
<ul>
<li>The model samples two parameters: <code>Omega_c</code> and <code>sigma8</code>.</li>
<li>A new cosmology object is constructed with those parameters.</li>
<li>Then the power spectrum prediction is computed and matched to data with a multivariate Gaussian likelihood.</li>
</ul>
<p>This setup mirrors what we do in practice: forward-model observables, simulate noisy data, and recover parameters via inference.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="full-field-inference-with-forward-models" class="slide level2" style="font-size: 18px;">
<h2>Full Field Inference with Forward Models</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<p><strong>Bayesian Inference using power spectrum data:</strong></p>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<p><strong>Bayesian Inference using full field data:</strong></p>
</div>
</div>
<div class="r-stack">
<div class="fragment fade-in-then-out" data-fragment-index="1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/bayes_pipeline_latent.svg" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<div class="fragment fade-out" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/FFI_full.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="assets/bayes/FFI_full_tuto.svg" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="fragment fade-in" data-fragment-index="1">
<ul>
<li><strong>Recap:</strong> Bayesian inference maps theory + data ‚Üí posterior</li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="2">
<ul>
<li><strong>Cosmological Forward models</strong>
<ul>
<li>Start from cosmological + latent parameters</li>
<li>Sample initial conditions</li>
<li>Evolve using <strong>N-body simulations</strong></li>
<li><strong>Predict convergence maps</strong> in tomographic bins</li>
</ul></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="3">
<ul>
<li><strong>Simulation-Based Inference</strong>
<ul>
<li>Compare predictions to real <strong>survey maps</strong></li>
<li>Build a <strong>likelihood</strong> from the forward model</li>
<li>Infer cosmological parameters from <strong>full field data</strong></li>
</ul></li>
</ul>
</div>
<div class="fragment fade-in" data-fragment-index="4">
<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 19px;">
<p><strong>Full Field vs.&nbsp;Summary Statistics</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 16px;">
<ul>
<li>Preserves <strong>non-Gaussian</strong> structure lost in summaries</li>
<li>Enables tighter constraints in <strong>nonlinear regimes</strong></li>
<li>Especially useful in <strong>high-dimensional</strong> inference problems</li>
<li>See: <em>Zeghal et al.&nbsp;(2024), Leclercq et al.&nbsp;(2021)</em></li>
<li>üîú a talk on this topic this Thursday</li>
</ul>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes for Final Slide (Full Field Inference):</strong></p>
<ul>
<li><p>We now shift to the most general and flexible form of inference ‚Äî using <strong>full field data</strong>.</p></li>
<li><p>This means we <strong>don‚Äôt extract summary statistics</strong> like <span class="math inline">\(C_\ell\)</span> ‚Äî instead, we model the forward process end-to-end, including simulations.</p></li>
<li><p>The green box shows the <strong>core components</strong> of this forward model pipeline:</p>
<ul>
<li>Start by <strong>sampling cosmological + latent parameters</strong> (e.g., initial conditions)</li>
<li>Use an <strong>N-body simulation</strong> to evolve structure</li>
<li>Predict observables (e.g., weak lensing convergence maps)</li>
<li>Compare the simulated maps to real observations to construct a <strong>likelihood</strong></li>
</ul></li>
<li><p>This approach <strong>preserves non-Gaussian information</strong>, which is critical in the nonlinear regime.</p></li>
<li><p>We‚Äôll focus specifically on the contents of the green box in the hands-on notebook:</p>
<ul>
<li>Sampling initial fields</li>
<li>Running a small-scale N-body simulation</li>
<li>Building a likelihood from simulation output</li>
</ul></li>
<li><p>It‚Äôs an extremely powerful method, and the frontier of cosmological inference.</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="conclusion" class="title-slide slide level1 center">
<h1>Conclusion</h1>

</section>
<section id="conclusion-why-bayesian-inference" class="slide level2">
<h2>Conclusion: Why Bayesian Inference?</h2>
<p><br> <br></p>
<h3 id="key-takeaways">üîë Key Takeaways</h3>
<ul>
<li><p><strong>Bayesian modeling</strong> lets you build flexible, extensible pipelines ‚Äî from analytical likelihoods to full forward simulations.</p></li>
<li><p>The <strong>JAX ecosystem</strong> (NumPyro, BlackJAX, jax-cosmo‚Ä¶) lets you focus on <strong>modeling</strong>, not math details.</p></li>
<li><p><strong>Gradients + differentiable simulators</strong> scale inference to complex, high-dimensional problems ‚Äî efficiently and transparently.</p></li>
<li><p>Bayesian tools are now mature, fast, and usable ‚Äî even for large cosmological models.</p></li>
</ul>
<div class="solutionbox">
<div class="solutionbox-header" style="font-size: 20px;">
<p><strong>Hands-On Notebooks:</strong></p>
</div>
<div class="solutionbox-body" style="font-size: 18px;">
<ul>
<li>Beginner Bayesian Inference with NumPyro &amp; Blackjax <a href="https://github.com/ASKabalan/Tutorials/blob/main/BDL2025/Exercises/01_Beginner.ipynb">here</a></li>
<li>Intermediate Bayesian Inference with NumPyro &amp; Blackjax <a href="https://github.com/ASKabalan/Tutorials/blob/main/BDL2025/Exercises/02_Intermediate.ipynb">here</a></li>
<li>some of the animation were made using this <a href="https://github.com/ASKabalan/Tutorials/blob/main/BDL2025/illustrations/HMC_vs_MCMC.ipynb">notebook</a></li>
</ul>
</div>
</div>
<h4 id="thank-you-for-your-attention">Thank you for your attention!</h4>
<aside class="notes">
<p><strong>Speaker Notes ‚Äì Conclusion Slide</strong></p>
<ul>
<li><p>Let‚Äôs wrap up with some key takeaways on <strong>why Bayesian inference matters</strong>, especially in cosmology:</p>
<ul>
<li><p>First, <strong>Bayesian modeling is modular and flexible</strong>. It gives us a way to go from simple analytic models to full simulator-based pipelines ‚Äî all under one framework.</p></li>
<li><p>The <strong>JAX ecosystem</strong> ‚Äî NumPyro, BlackJAX, jax-cosmo ‚Äî gives you a complete toolchain. You don‚Äôt have to worry about math-heavy derivations or custom samplers. You can focus on the science and modeling.</p></li>
<li><p>A major strength is the ability to leverage <strong>gradients and differentiable simulators</strong>. That means you can scale inference even for models with thousands or millions of parameters ‚Äî like field-level inference.</p></li>
<li><p>And importantly, the tools are <strong>mature and fast</strong>. These aren‚Äôt just research toys ‚Äî they‚Äôre ready for real problems.</p></li>
</ul></li>
<li><p>Now it‚Äôs your turn. You‚Äôll have access to <strong>two hands-on notebooks</strong>:</p>
<ul>
<li>One walks you through Bayesian regression and cosmological inference with NumPyro.</li>
<li>The other dives into field-level inference and simulation-based modeling.</li>
</ul></li>
<li><p>This is where things become tangible ‚Äî you‚Äôll code your own inference pipeline, simulate structure formation, and run real MCMC samplers.</p></li>
<li><p>That‚Äôs the power of combining <strong>Bayesian ideas</strong> with <strong>modern tools</strong> ‚Äî and that‚Äôs where the future of cosmological inference is headed.</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Bayesian Deep Learning Workshop , 2025</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'slide',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/ASKabalan\.github\.io\/slides\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>