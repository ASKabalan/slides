---
title: "Differentiable and distributed Particle-Mesh n-body simulations"
author: "Wassim Kabalan, François Lanusse, Alexandre Boucaud"
footer: "LSST France, 2024"
format:
  revealjs:
    theme: [default, css/custom.scss]
    incremental: false   
    transition: slide
    background-transition: slide
    presentation-size: max-scale
    template-partials:
      - css/title-slide.html
output: revealjs

code-block-border-left: "#31BAE9"
title-slide-attributes:
  data-background-image: "assets/lsst_bg.jpg"
  data-background-size: fill
  data-background-opacity: "0.5"

logo1: '![](assets/AIM.png){fig-align="center"width=10%} ![](assets/APC.png){fig-align="center" width=10%}'



---

## Traditional cosmological inference

<br />

### Bayesian inference in cosmology

- We need to infer the cosmological parameters $\theta$ that generated an observartion $x$

<font size="4">$$p(\theta | x ) \propto \underbrace{p(x | \theta)}_{\mathrm{likelihood}} \ \underbrace{p(\theta)}_{\mathrm{prior}}$$</font>


:::: {.columns}

::: {.column width="40%"}

::: {.fragment fragment-index=1 .fade-in-then-out }

![](assets/hsc-corr-function.png){.absolute top=180 left=25 width="300"}

:::

::: {.fragment fragment-index=2}

![](assets/hsc_constraints.png){.absolute top=200 left=25 width="350"}

:::

:::

::: {.column width="60%"}

::: {.fragment fragment-index=1}
<br />
 ➢  &emsp;Compute **summary statistics** based on the 2-point correlation function of the shear field
:::

::: {.fragment fragment-index=2}
<br />
 ➢  &emsp;Run an **MCMC** chain to recover the posterior distribution of the cosmological parameters, using an **analytical likelihood**
:::

:::

::::

<br />

::: {.fragment fragment-index=3}

:::{.solutionbox}

::::{.solutionbox-header}
Limitations
::::

::::{.solutionbox-body}
- Simple summary statistics assume Gaussianity
- The need to compute an analytical likelihood
::::

:::

:::

---

### Beyond 2 point statistics : Full field inference

<br />


![](assets/simu.png){.nostretch fig-align="center" width="600px"}


::: {.fragment}

➕  &emsp;No longer need to compute the likelihood analytically
<br />
<br />
➖ &emsp;We need to infer the joint posterior $p(\theta, z | x)$ before marginalization to get $p(\theta | x) = \int p(\theta, z | x) \, dz$

::: 

::: {.fragment}

:::{.solutionbox}


::::{.solutionbox-header}
Possible solutions
::::

::::{.solutionbox-body}
- **Hamiltonian Monte Carlo**
- **Variational Inference**
- **Dimensionality reduction using Fisher Information Matrix**

*All require a differentiable fast forward model*

::::

:::

:::

::: {.fragment}

➢  &emsp; We need a fast, differentiable and precise cosmological simulations

:::

---

### Fast Particle-mesh simulations

<br />
<br />

:::: {.columns}

::: {.column width="50%"}

#### Numerical scheme

::: {.fragment fragment-index=1}

➢  &emsp;Interpolate particles on a grid to estimate mass density

:::

::: {.fragment fragment-index=2}

➢  &emsp;Estimate gravitational force on grid points by FFT

:::

::: {.fragment fragment-index=3}

➢  &emsp;Interpolate forces back on particles

:::

::: {.fragment fragment-index=4}

➢  &emsp;Update particle velocity and positions, and iterate 

:::

::: 

::: {.column width="50%"}

:::{r-stack}


::: {.fragment fragment-index=1 .fade-in-then-out}

![](assets/FastPM_Init.gif){.absolute top=50 left=400 width="800"}

:::


::: {.fragment fragment-index=2 .fade-in-then-out}

![](assets/FastPM_LPT.gif){.absolute top=50 left=400 width="800"}


[$\begin{array}{c}{{\nabla^{2}\phi=-4\pi G\rho}}\\\\ {{f(\vec{k})=i\vec{k}k^{-2}\rho(\vec{k})}}\end{array}$]{.absolute top=500 right=160}

::: 

::: {.fragment fragment-index=3}

![](assets/FastPM_ODE.gif){.absolute top=50 left=400 width="800"}



:::

:::


::: 

:::: 

::: {.fragment fragment-index=5 }

<br />
<br />
<br />
<br />
<br />
<br />


:::{.solutionbox}

::::{.solutionbox-body}

- Fast and simple, at the cost of approximating short range interactions. 
- It is essentially a series of FFTs and interpolations
- It is differentiable and can run on GPUs

::::

:::

:::

---

## JAX : Automatic differentiation and Hardware acceleration {auto-animate="true"}

![](assets/JaxLogo.png){.absolute top=60 right=25 width=200px}

<br />
<br />
<br />
<br />
<br />
<br />

``` python
import numpy as np


def multiply_and_add(a, b, c):
    return np.dot(a, b) + c


a, b, c = np.random.normal(size=(3, 32, 32))
result = multiply_and_add(a, b, c)
```
<br />

::: {.fragment fragment-index=1 .fade-in-then-out }

``` python
import jax
import jax.numpy as jnp


def multiply_and_add(a, b, c):
    return jnp.dot(a, b) + c


key = jax.random.PRNGKey(0)
a, b, c = jax.random.normal(key, (3, 32, 32))

result = multiply_and_add(a, b, c) 

```

::: 


## JAX : Automatic differentiation and Hardware acceleration {auto-animate="true"}

![](assets/JaxLogo.png){.absolute top=60 right=25 width=200px}

<br />
<br />
<br />
<br />
<br />
<br />


``` python
import jax
import jax.numpy as jnp


def multiply_and_add(a, b, c):
    return jnp.dot(a, b) + c


key = jax.random.PRNGKey(0)
a, b, c = jax.random.normal(key, (3, 32, 32))

result = multiply_and_add(a, b, c) 

```

## JAX : Automatic differentiation and Hardware acceleration {auto-animate="true"}

![](assets/JaxLogo.png){.absolute top=60 right=25 width=200px}

<br />
<br />
<br />
<br />
<br />
<br />


``` python
import jax
import jax.numpy as jnp

@jax.jit
def multiply_and_add(a, b, c):
    return jnp.dot(a, b) + c


key = jax.random.PRNGKey(0)
a, b, c = jax.random.normal(key, (3, 32, 32))

result = multiply_and_add(a, b, c) 
gradient = jax.grad(multiply_and_add)(a, b, c)

```

<br />
<br />

:::{.solutionbox}

::::{.solutionbox-header}

JAX : Numpy + Autograd + GPU

::::

::::{.solutionbox-body}

 - <span style="color:violet;">jax.grad</span> uses automatic differentiation to compute the gradient of the function
 - <span style="color:violet;">jax.jit</span> compiles the function to run on GPUs

::::

:::
---

### JaxPM : A differentiable Particle-Mesh simulation

#### FastPM simulation in a few lines of code

<p style="display: flex; align-items: center; position: absolute; top: 10px; left: 700px;">
  <img src="assets/github_logo.png" alt="GitHub Logo" style="width: 5%; margin-right: 10px;">
  <a href="https://github.com/DifferentiableUniverseInitiative/JaxPM">DifferentiableUniverseInitiative/JaxPM</a>
</p>


:::: {.columns}

::: {.column width="50%"}

<div style="font-size: 83%">

<div style="position: absolute; top: 75px; left: 0px;">

```{.python }
mesh_shape = [64, 64, 64]
box_size = [64., 64., 64.]
snapshots = jnp.linspace(0.1, 1., 2)

@jax.jit
def run_simulation(omega_c, sigma8):
    # Create a small function to generate the matter power spectrum
    k = jnp.logspace(-4, 1, 128)
    pk = jc.power.linear_matter_power(
        jc.Planck15(Omega_c=omega_c, sigma8=sigma8), k)
    pk_fn = lambda x: jc.scipy.interpolate.interp(x.reshape([-1]), k, pk
                                                  ).reshape(x.shape)

    # Create initial conditions
    initial_conditions = linear_field(mesh_shape,
                                      box_size,
                                      pk_fn,
                                      seed=jax.random.PRNGKey(0))

    # Create particles
    particles = jnp.stack(jnp.meshgrid(*[jnp.arange(s) for s in mesh_shape]),
                          axis=-1).reshape([-1, 3])

    cosmo = jc.Planck15(Omega_c=omega_c, sigma8=sigma8)

    # Initial displacement
    dx, p, f = lpt(cosmo, initial_conditions, particles, 0.1)
    field = dx + particles

    # Evolve the simulation forward
    ode_fn = make_ode_fn(mesh_shape)
    term = ODETerm(lambda t, state, args: jnp.stack(ode_fn(state, t, args), axis=0))
    solver = Dopri5()

    stepsize_controller = PIDController(rtol=1e-7, atol=1e-7)
    res = diffeqsolve(term, solver, t0=0.1, t1=1., dt0=0.01, y0=jnp.stack([dx, p],axis=0), 
                       args=(cosmo , kvec),
                       stepsize_controller=stepsize_controller,
                       saveat=SaveAt(ts=snapshots))

    # Return the simulation volume at requested
    return field, res, initial_conditions

field, res, initial_conditions = run_simulation(0.25, 0.8)


```


</div>

</div>

:::

::: {.column width="50%"}

::: {.fragment fragment-index=1} 

![](assets/FastPM_ODE3D.gif){.absolute top=50 left=400 width="900"}

:::

:::

::::

::: {.fragment fragment-index=7} 


[***Is everything solved ?***]{.absolute top=650 left=100}

::: 

---

### Fast Particle-mesh scaling

#### Current FastPM implementation

:::aside


:::


➢  &emsp;(Poqueres et al. 2021) : $64^3$ mesh size, on a 1000 Mpc/h box

➢  &emsp;(Li et al. 2022) : $512^3$ mesh size,  using [pmwd](https://github.com/eelregit/pmwd)

::: {.fragment fragment-index=1 }

![](assets/depict_gathered.png){.absolute top=30 right=0 width="20%"}

::: 

:::: {.columns}

::: {.column width="50%"}

::: {.r-stack}

::: {.fragment fragment-index=1 .fade-in-then-out}

![Initial Conditions with a 1024 mesh](assets/initial_conditions_1024.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=2 .fade-in-then-out}

![Initial Conditions with a 512 mesh](assets/initial_conditions_512.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=3 .fade-in-then-out}

![Initial Conditions with a 256 mesh](assets/initial_conditions_256.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=4 .fade-in-then-out}

![Initial Conditions with a 128 mesh](assets/initial_conditions_128.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=5 .fade-in-then-out}

![Initial Conditions with a 64 mesh](assets/initial_conditions_64.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=6}

<!-- 512 -->

![Power spectrum comparison](assets/power_spec.png){.nostretch fig-align="center" width="400px"}

::: 

:::

::: 

::: {.column width="50%"}

::: {.r-stack}

::: {.fragment fragment-index=1 .fade-in-then-out}

![Final field with a 1024 mesh](assets/LPT_density_field_z0_1024.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=2 .fade-in-then-out}

![Final field with a 512 mesh](assets/LPT_density_field_z0_512.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=3 .fade-in-then-out}

![Final field with a 256 mesh](assets/LPT_density_field_z0_256.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=4 .fade-in-then-out}

![Final field with a 128 mesh](assets/LPT_density_field_z0_128.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=5 .fade-in-then-out}

![Final field with a 64 mesh](assets/LPT_density_field_z0_64.png){.nostretch fig-align="center" width="400px"}

::: 

::: {.fragment fragment-index=6}

![Final field with a 1024 mesh](assets/LPT_density_field_z0_1024.png){.nostretch fig-align="center" width="400px"}

::: 

::: 

:::

::::

::: {.fragment fragment-index=9}

:::{.solutionbox}

::::{.solutionbox-header}

Scaling

::::

::::{.solutionbox-body}

We need a fast, differentiable and <span style="color:violet;">Scalable</span> Particle-Mesh simulation

::::

::: 

::: 



---

### Scaling on modern hardware

#### Size of a FastPM simulation


![](assets/simulation_gpu_sizes.png){.nostretch fig-align="center" width="650"}


::: {.fragment .fragment-index-1}


#### Scaling on multiple GPUs


::: {layout="[20 , 30 , 50]" layout-valign="bottom" layout-align="bottom"}

![Single GPU (80GB)](assets/jax-1gpu.png){width="55%"}


![Single Node (8x80GB)](assets/jax-1node.png){width="55%"}


![Muti Node ( $\infty$ )](assets/jax-multi-node.png){width="90%"}

::: 

:::
---


## Distributed Fast Fourier Transform {auto-animate="true"}

➢  &emsp;only operation that requires communication is the FFT

<br/>

#### Jaxdecomp

:::: {.columns}

::: {.column width="50%"}

```python
import jax
import jax.numpy as jnp

field = jax.random.normal(jax.random.PRNGKey(0), (1024, 1024, 1024))
k_field = jnp.fft.fftn(field)
```

:::

::: {.column width="50%"}

:::

::::

---

## Distributed Fast Fourier Transform {auto-animate="true"}

➢  &emsp;only operation that requires communication is the FFT

<br/>

#### Jaxdecomp

<p style="display: flex; align-items: center; position: absolute; top: 10px; left: 600px;">
  <img src="assets/github_logo.png" alt="GitHub Logo" style="width: 5%; margin-right: 10px;">
  <a href="https://github.com/DifferentiableUniverseInitiative/jaxDecomp">DifferentiableUniverseInitiative/jaxDecomp</a>
</p>

:::: {.columns}

::: {.column width="50%"}

```python
import jax
import jax.numpy as jnp
import jaxdecomp

devices = mesh_utils.create_device_mesh((2, 2))
mesh = jax.sharding.Mesh(devices, axis_names=('x', 'y'))
sharding = jax.sharding.NamedSharding(mesh, P('x', 'y'))

# Create gaussian field distributed across the mesh
field = jax.make_array_from_single_device_arrays(
    shape=mesh_shape,
    sharding=sharding,
    arrays=[jax.random.normal(jax.random.PRNGKey(rank), (512, 512, 1024))])

k_field = jaxdecomp.fft.pfft3d(field)


```

:::{.fragment fragment-index=3}


:::{.solutionbox}

::::{.solutionbox-header}

JaxDecomp features

::::

::::{.solutionbox-body}

➢  &emsp;jaxDecomp supports 2D and 1D decompositions

➢  &emsp;Works for multi-node FFTs

➢  &emsp;is differentiable

➢  &emsp;The package is also provided as a standalone library


::::

:::

:::

:::

::: {.column width="50%"}

:::{.fragment fragment-index=2}

![](assets/decomp2d.gif){.absolute top=50 left=400 width="900"}

:::

::: 

::::

---

### Scaling of Distributed FFT operations

![](assets/single_precision_gpus.png){.absolute top=50 left=0 width="1000"}


---

## Halo exchange in distributed simulations

::: {.fragment fragment-index=1 .fade-in-then-out}

![](assets/depict_gathered.png){.absolute top=30 right=20 width="20%"}

::: 

::: {.fragment fragment-index=2 }

![](assets/depict_split.png){.absolute top=30 right=20 width="20%"}

::: 

:::{.r-stack}

:::{.fragment fragment-index=1 .fade-in-then-out}

![Initial Field](assets/initial_conditions_1024.png){.nostretch  width="400px"}

:::

:::{.fragment fragment-index=2 .fade-in-then-out}

:::{layout="[[1] , [1] , [1] , [1]]" layout-valign="center" layout-align="center"}

![First slice](assets/initial_conditions_0_no_halo.png){.nostretch fig-align="center" width="400px"}

![Second slice](assets/initial_conditions_1_no_halo.png){.nostretch fig-align="center" width="400px"}

![Third slice](assets/initial_conditions_2_no_halo.png){.nostretch fig-align="center" width="400px"}

![Fourth slice](assets/initial_conditions_3_no_halo.png){.nostretch fig-align="center" width="400px"}

:::

:::

:::{.fragment fragment-index=3 .fade-in-then-out}

:::{layout="[[1] , [1] , [1] , [1]]" layout-valign="center" layout-align="center"}

![First slice](assets/LPT_density_field_z0_0_no_halo.png){.nostretch fig-align="center" width="400px"}

![Second slice](assets/LPT_density_field_z0_1_no_halo.png){.nostretch fig-align="center" width="400px"}

![Third slice](assets/LPT_density_field_z0_2_no_halo.png){.nostretch fig-align="center" width="400px"}

![Fourth slice](assets/LPT_density_field_z0_3_no_halo.png){.nostretch fig-align="center" width="400px"}

:::

:::

:::{.fragment fragment-index=4 .fade-in-then-out}

![LPT Field](assets/LPT_density_field_z0_1024_no_halo.png){.nostretch fig-align="center" width="400px"}

:::


:::{.fragment fragment-index=5}

![LPT Field](assets/LPT_density_field_z0_1024.png){.nostretch fig-align="center" width="400px"}

:::

:::

:::{.fragment fragment-index=5}

<div style="position: absolute; top: 75px; left: 0px; width: 500px; font-size: 100%">

```python
from jaxdecomp import halo_exchange

halo_size = 128
field = halo_exchange(field, halo_extent=halo_size)

```

</div>

:::

---

### Distributed JaxPM Particle-Mesh simulations 


![](assets/LPT_density_field_z0_2048.png){.nostretch fig-align="center" width="400px"}

:::{.solutionbox}

::::{.solutionbox-header}

Distributed FastPM simulations

::::

::::{.solutionbox-body}

➢  &emsp;Multi host version of <span style="color:violet;">JaxPM</span> using <span style="color:violet;">jaxDecomp</span>

➢  &emsp;For a $2048^3$ LPT simulation ran on 16 GPUs runs in under a second on Jean-Zay super computer

➢  &emsp;We aim to run a $8192^3$ Particle-mesh simulation on 160 GPUs 

::::

:::


---


## Conclusion {background-image="assets/LPT_density_field_z0_2048.jpg"}

<br/>
<br/>
<br/>
<br/>

:::{.solutionbox}

::::{.solutionbox-header}

Distruibuted Particle-Mesh simulations for cosmological inference

::::

::::{.solutionbox-body}

 - A shift from analytical likelihoods to full field inference
   - The need for fast differentiable simulators
   - Particle-Mesh as simulators for full field inference
   - Distributed fourrier transforms that work on multi-node HPC using <span style="color:violet;">jaxDecomp</span>
   - Highly scalable LPT simulations using <span style="color:violet;">JaxPM</span>
 - Still subject to some challenges 
   - Some issues with the ODE solving step
   - Only Euler gives decent results.

::::


:::

---

## 

---
